{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a353b115",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985de74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1dfa0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da512f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('x28.txt', sep = '\\s+', header=None)\n",
    "data = data.drop(columns = 0)\n",
    "data.columns = ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'B']\n",
    "data = data.astype(\"float\")\n",
    "X = data.iloc[:,0:15].to_numpy()\n",
    "Y = data.iloc[:,15].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719789e6",
   "metadata": {},
   "source": [
    "## Normalize and add ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8937d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "ones = np.array([[1] for _ in range(X_normalized.shape[0])])\n",
    "Xbar = np.column_stack((ones, X_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d54e8c",
   "metadata": {},
   "source": [
    "## Triá»ƒn khai RidgeRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6f664cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def fit(self, X_train, Y_train, LAMBDA):\n",
    "        assert len(X_train.shape) == 2  and X_train.shape[0] == Y_train.shape[0]\n",
    "        A = np.dot(X_train.T, X_train) + LAMBDA*np.identity(X_train.shape[1])\n",
    "        W = np.linalg.inv(A).dot(X_train.T).dot(Y_train)\n",
    "        return W\n",
    "    \n",
    "    def fit_gradient_descent(self, X_train, Y_train, LAMBDA, learning_rate, max_num_epoch=100, batch_size=20):\n",
    "        W = np.random.rand(X_train.shape[1])\n",
    "        last_loss = 1e9\n",
    "        for ep in range(max_num_epoch):\n",
    "            arr = np.array(range(X_train.shape[0]))\n",
    "            np.random.shuffle(arr)\n",
    "            X_train = X_train[arr]\n",
    "            Y_train = Y_train[arr]\n",
    "            total_minibatch = int(np.ceil(X_train.shape[0]/batch_size))\n",
    "            for i in range(total_minibatch):\n",
    "                index = i * batch_size\n",
    "                X_train_sub = X_train[index:index+batch_size]\n",
    "                Y_train_sub = Y_train[index:index+batch_size] \n",
    "                grad = np.dot(X_train_sub.T, X_train_sub.dot(W) - Y_train_sub) + LAMBDA*W\n",
    "                W = W - learning_rate*grad\n",
    "            new_loss = self.compute_RSS(self.predict(W, X_train), Y_train)\n",
    "            if np.abs(new_loss - last_loss) <= 1e-5:\n",
    "                break\n",
    "            last_loss = new_loss\n",
    "        return W\n",
    "    \n",
    "    def predict(self, W, X_new):\n",
    "        X_new = np.array(X_new)\n",
    "        Y_new = np.dot(X_new, W)\n",
    "        return Y_new\n",
    "    \n",
    "    def compute_RSS(self, Y_new, Y_predicted):\n",
    "        loss = (1/Y_new.shape[0])*np.sum((Y_new - Y_predicted)**2)\n",
    "        return loss\n",
    "    \n",
    "    def get_the_best_LAMBDA(self, X_train, Y_train):\n",
    "        def cross_validation(num_folds, LAMBDA):\n",
    "            row_ids = np.array(range(X_train.shape[0]))\n",
    "            ending_ids = len(row_ids) - len(row_ids)%num_folds\n",
    "            valid_ids = np.split(row_ids[:ending_ids], num_folds)\n",
    "            valid_ids[-1] = np.append(valid_ids[-1], row_ids[ending_ids:])\n",
    "            train_ids = [[k for k in row_ids if k not in valid_ids[i]] for i in range(num_folds)]\n",
    "            total_RSS = 0\n",
    "            for i in range(num_folds):\n",
    "                valid_part = {'X': X_train[valid_ids[i]], 'Y': Y_train[valid_ids[i]]}\n",
    "                train_part = {'X': X_train[train_ids[i]], 'Y': Y_train[train_ids[i]]}\n",
    "                W = self.fit_gradient_descent(train_part['X'], train_part['Y'], LAMBDA, learning_rate=1e-3)\n",
    "                Y_predicted = self.predict(W, valid_part['X'])\n",
    "                total_RSS += self.compute_RSS(Y_test, Y_predicted)\n",
    "            return total_RSS/num_folds\n",
    "            \n",
    "        \n",
    "        def range_scan(best_LAMBDA, minimum_RSS, LAMBDA_values):\n",
    "            for current_LAMBDA in LAMBDA_values:\n",
    "                aver_RSS = cross_validation(5, current_LAMBDA)\n",
    "                if aver_RSS < minimum_RSS:\n",
    "                    minimum_RSS = aver_RSS\n",
    "                    best_LAMBDA = current_LAMBDA\n",
    "            return best_LAMBDA, minimum_RSS\n",
    "        #Initalize\n",
    "        best_LAMBDA, minimum_RSS = range_scan(best_LAMBDA=0, minimum_RSS=10000**2, LAMBDA_values=range(50))\n",
    "        LAMBDA_values = [k*1./1000 for k in range(max(0, (best_LAMBDA - 1)*1000), (best_LAMBDA+1)*1000, 1)] #step size = 0.001\n",
    "        \n",
    "        #Scan\n",
    "        best_LAMBDA, minimum_RSS = range_scan(best_LAMBDA=best_LAMBDA, minimum_RSS=minimum_RSS, LAMBDA_values=LAMBDA_values)\n",
    "        \n",
    "        return best_LAMBDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dde032",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e9f16fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LAMBDA: 1.294\n",
      "RSS: 2297.672646377029\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = Xbar[:50], Y[:50]\n",
    "X_test, Y_test = Xbar[50:], Y[50:]\n",
    "\n",
    "ridgeRegression = RidgeRegression()\n",
    "\n",
    "best_LAMBDA = ridgeRegression.get_the_best_LAMBDA(X_train, Y_train)\n",
    "print('Best LAMBDA:', best_LAMBDA)\n",
    "\n",
    "W_learned = ridgeRegression.fit(X_train, Y_train, best_LAMBDA)\n",
    "Y_predicted = ridgeRegression.predict(W_learned, X_test)\n",
    "RSS = ridgeRegression.compute_RSS(Y_test, Y_predicted)\n",
    "print('RSS:', RSS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
